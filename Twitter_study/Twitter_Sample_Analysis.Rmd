---
title: "Twitter_Sample_Analysis"
output: html_notebook
---



```{r Libraries, include = F}
library(tidytext) 
library(tidyverse)
library(topicmodels) 
library(ldatuning)
library(textstem) 
library(SnowballC) 
library(tm)
library(car) 
```


```{r Import-Data, include = F}
dat <- read_csv("wfh_twitter_data.csv")

```




```{r Data-Cleaning}

# set first column as row_id
twitter_data <- dat %>%
  rename(row_id = X1) %>%
  filter(!row_id == "author_id")


# Convert to basic ASCII text to avoid meaningless characters
twitter_data$text <- as.character(twitter_data$text) 
twitter_data$text <- iconv(twitter_data$text, to = "ASCII", sub = " ")  

twitter_data$text <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", twitter_data$text)  # Remove the "RT" (retweet) and usernames 
twitter_data$text <- gsub("http.+ |http.+$", " ", twitter_data$text)  # Remove html links
twitter_data$text <- gsub("http[[:alnum:]]*", "", twitter_data$text)
twitter_data$text <- gsub("[[:punct:]]", " ", twitter_data$text)  # Remove punctuation
twitter_data$text <- gsub("[ |\t]{2,}", " ", twitter_data$text)  # Remove tabs
twitter_data$text <- gsub("^ ", "", twitter_data$text)  # Leading blanks
twitter_data$text <- gsub(" $", "", twitter_data$text)  # Lagging blanks
twitter_data$text <- gsub(" +", " ", twitter_data$text) # General spaces 
twitter_data$text <- gsub('[[:digit:]]+', '', twitter_data$text)



# additional filtering 
twitter_data$text <- tolower(twitter_data$text)

twitter_data %>%
   sample_n(10000) 




# remove twitter-specific stop words
#twitter_cleaned <- twitter_data %>%
   filter(!grepl("t.co", text)) %>%
   filter(!grepl("https", text)) %>%
  filter(!grepl("i'm", text)) %>%
  filter(!grepl("amp", text)) %>%
  filter(!grepl("it's", text)) %>%
  filter(!grepl("don't", text)) %>%
  filter(!grepl("can't", text)) %>%
  filter(!grepl("home from work", text)) %>%
  filter(!grepl("IL", text)) %>%
  filter(!grepl("II", text)) %>%
  filter(!grepl("lol", text)) %>%
  filter(!grepl("didn", text)) %>%
  filter(!grepl("ain", text)) %>%
  filter(!grepl("ve", text)) %>%
  filter(!grepl("doesn", text)) %>%
  filter(!grepl("at", text)) %>%
  filter(!grepl("ii", text))

# convert specific fields to appropriate data type 

twitter_cleaned$like_count <- as.numeric(twitter_cleaned$like_count) 



```



Initial topic modeling 
```{r Topic-Modeling}

# create dtm for TM; remove stop words
# using stemming 
twitter_dtm <- twitter_cleaned %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
    mutate(stem = wordStem(word)) %>%
  count(row_id, stem) %>%
  cast_dtm(document = row_id, term = stem, value = n) %>%
  as.matrix()  




# not stem
#twitter_dtm <- twitter_cleaned %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  count(row_id, word) %>%
  cast_dtm(document = row_id, term = word, value = n) %>%
  as.matrix()

         

# determine ideal number of topic models; visualize
# first, using just the Cao et al. 2009 method via Finch et al. (2019)
# the Cao 2009 method minmizes density 

seed<- 59127
number_topics <- FindTopicsNumber(
  twitter_dtm,
  topics = seq(from = 2, to = 25, by = 1),
  metrics = c("CaoJuan2009"),
  method = "GIBBS",
  
  control=list(seed = seed),
  mc.cores = 2L,
  verbose = TRUE
)

# it appears that an optimal number of topics are 2 or 6
FindTopicsNumber_plot(number_topics) 



# identify k topics again using the broader list of metrics
result <- FindTopicsNumber(
  reasons_dtm,
  topics = seq(from = 2, to = 15, by = 1),
  metrics = c("CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "VEM",
  control = list(seed = 831),
  mc.cores = 2L,
  verbose = TRUE)

FindTopicsNumber_plot(result)


```






```{r}
# run a correlated topic model with k =  
ctm_1 <- CTM(twitter_dtm, 
    k = 12, 
    method = "VEM")

# create similar LDA 

#lda_six <- LDA(reasons_dtm,k = 6) 

# tidy the CTM model output 

twitter_ctm_topics <- ctm_1 %>%
  tidy(matrix = "beta") %>%
  arrange(desc(beta))

# arrange top 15 terms by each topic 

twitter_word_probs<- twitter_ctm_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 15) %>% 
  ungroup() %>%
  arrange(topic, -beta)

twitter_word_probs %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() + theme(axis.text=element_text(size=12)) 

```




```{r Common-Words}


```


```{r}
# assign topic from CTM to observations 
# use the function topics() from topicmodels library to assign the most
# likely topics for each document (in this case combined reasons) 

ctm_assignments <- data.frame(topics(ctm_1)) 
ctm_assignments$row_id <- rownames(ctm_assignments) 
colnames(ctm_assignments) <- c("topic_assigned", "row_id") 

# join topic assignment outputs with original data set using dyply's inner_join() 

topics_assigned <- inner_join(x = twitter_cleaned, 
           y = ctm_assignments, 
           by = "row_id") 
  
# check distribution of topics assigned
# shows even split between two topics 
table(topics_assigned$topic_assigned) 
```


```{r Dummy-Coding}
table(topics_assigned$topic_assigned) 

# for a 4 topic solution
# note: this will change based on the optimal number of topics identified above 
# in the study, the topic model will first be run and inter-rater reliability
# will be calculated before this step below, where the topics are assigned back 
# to the data set 

topics_assigned$topic_1 <- ifelse(topics_assigned$topic_assigned == '1', 1, 0)
topics_assigned$topic_2 <- ifelse(topics_assigned$topic_assigned == '2', 1, 0)
topics_assigned$topic_3 <- ifelse(topics_assigned$topic_assigned == '3', 1, 0)
topics_assigned$topic_4 <- ifelse(topics_assigned$topic_assigned == '4', 1, 0)

topics_assigned$topic_5 <- ifelse(topics_assigned$topic_assigned == '5', 1, 0)

topics_assigned$topic_6 <- ifelse(topics_assigned$topic_assigned == '6', 1, 0)

#topics_assigned$topic_7 <- ifelse(topics_assigned$topic_assigned == '7', 1, 0)

#topics_assigned$topic_8 <- ifelse(topics_assigned$topic_assigned == '8', 1, 0)


```


Before running analyses
```{r Data-Cleaning-2}


# create factor variable (alternative to manual dummy coding above)
topics_assigned$topic_factor <- factor(x = topics_assigned$topic_assigned, 
                          levels = c(1, 2, 3, 4, 5, 6),
                          labels = c("Topic1", "Topic2", "Topic3", "Topic4", "Topic5", "Topic6")) 



# check data class for count data - likes and retweets
# remove all NA values from a
table(is.na(topics_assigned$like_count)) 



# convert retweet_count and reply_count fields to numeric 

topics_assigned$retweet_count <- as.numeric(topics_assigned$retweet_count) 
table(is.na(topics_assigned$retweet_count)) 

topics_assigned$reply_count <- as.numeric(topics_assigned$reply_count) 
table(is.na(topics_assigned$reply_count)) 

```



```{r Regression}

# standardized outcome variable 
std_topic_df <- topics_assigned %>% 
  mutate(std_likes <- scale(like_count)) 


# model comparison 

lmF <- lm(like_count ~ topic_factor, 
          data = topics_assigned) 
lmF %>%
  summary() 


lm_reduced <- lm(like_count ~ 1, data = topics_assigned) 
anova(lm_reduced) 

lm_topics <- lm(like_count ~ 1 + topic_factor, 
              data = topics_assigned) 

anova(lm_topics)   
anova(lm_reduced, lm_topics)
summary(lm_topics) 
lm_full %>% summary()  

mod_comparison_1 <- anova(lm_reply, lm_full)
mod_comparison_1 

```


Set maximum threshold for word frequency.
Words that occur too often across tweets are likely to reduce the model's ability 
To generate meaningfully differentiated topics 

```{r Word-Min-Max-Threshold}

# twitter_cleaned ; df originally fed into first TM above 
# set a min and max threshold for input into topic model 
# view top terms in corpus
twitter_ctm_topics %>%
  mutate(total = beta*length(term)) %>%
  filter(total > 500)


# str_remove_all() 
twitter_2 <- twitter_cleaned %>%
  mutate(text1 = str_remove_all(text, " home | amp | return"))  



```




