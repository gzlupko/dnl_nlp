---
title: "Twitter_Sample_Analysis"
output: html_notebook
---



```{r Libraries, include = F}
library(tidytext) 
library(tidyverse)
library(topicmodels) 
library(ldatuning)
library(textstem) 
library(SnowballC) 
library(tm)
library(car) 
library(wesanderson) 
```


```{r Import-Data, include = F}
dat <- read_csv("wfh_twitter_data.csv")
```



```{r Data-Cleaning}

# set first column as row_id
twitter_data <- dat %>%
  rename(row_id = X1) %>%
  filter(!row_id == "author_id")


# Convert to basic ASCII text to avoid meaningless characters
twitter_data$text <- as.character(twitter_data$text) 
twitter_data$text <- iconv(twitter_data$text, to = "ASCII", sub = " ")  

twitter_data$text <- gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", twitter_data$text)  # Remove the "RT" (retweet) and usernames 
twitter_data$text <- gsub("http.+ |http.+$", " ", twitter_data$text)  # Remove html links
twitter_data$text <- gsub("http[[:alnum:]]*", "", twitter_data$text)
twitter_data$text <- gsub("[[:punct:]]", " ", twitter_data$text)  # Remove punctuation
twitter_data$text <- gsub("[ |\t]{2,}", " ", twitter_data$text)  # Remove tabs
twitter_data$text <- gsub("^ ", "", twitter_data$text)  # Leading blanks
twitter_data$text <- gsub(" $", "", twitter_data$text)  # Lagging blanks
twitter_data$text <- gsub(" +", " ", twitter_data$text) # General spaces 
twitter_data$text <- gsub('[[:digit:]]+', '', twitter_data$text)


# additional filtering steps: 
twitter_data$text <- tolower(twitter_data$text) # text to lower case 

# create vector of strings to remove from tweets 

#text_remove <- c("t.co, https, i'm, amp, it's, don't, can't, 
#home from work, IL, II, lol, didn't, ain't, doesn't, at, i")


# The words to remove are bound with \\b so that they are not removed from the 
#beginning, middle, or end or other words

#twitter_cleaned <- twitter_data%>%   
  mutate(tweets_cleaned = 
           str_remove_all(text, 
          regex(str_c("\\b",text_remove, "\\b", collapse = '|'), 
          ignore_case = T)))

   
#generate random sample of tweets to limit size
twitter_cleaned <- twitter_data %>%
   sample_n(700) 
   
# convert specific fields to appropriate data type 

twitter_cleaned$like_count <- as.numeric(twitter_cleaned$like_count) 


```



Initial topic modeling 
```{r Topic-Modeling}

# create dtm for TM; remove stop words
# using stemming 
twitter_dtm <- twitter_cleaned %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
    mutate(stem = wordStem(word)) %>%
  count(row_id, stem) %>%
  cast_dtm(document = row_id, term = stem, value = n) %>%
  as.matrix()  


# not stem
#twitter_dtm <- twitter_cleaned %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  count(row_id, word) %>%
  cast_dtm(document = row_id, term = word, value = n) %>%
  as.matrix()


# determine ideal number of topic models; visualize
# first, using just the Cao et al. 2009 method via Finch et al. (2019)
# the Cao 2009 method minmizes density 

seed<- 59127
number_topics <- FindTopicsNumber(
  twitter_dtm,
  topics = seq(from = 2, to = 15, by = 1),
  metrics = c("CaoJuan2009"),
  method = "GIBBS",
  
  control=list(seed = seed),
  mc.cores = 2L,
  verbose = TRUE
)

# it appears that an optimal number of topics are 2 or 6
FindTopicsNumber_plot(number_topics) 



# identify k topics again using the broader list of metrics
result <- FindTopicsNumber(
  reasons_dtm,
  topics = seq(from = 2, to = 15, by = 1),
  metrics = c("CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "VEM",
  control = list(seed = 831),
  mc.cores = 2L,
  verbose = TRUE)

FindTopicsNumber_plot(result)


```





```{r}
# run a correlated topic model with k =  
ctm_1 <- CTM(twitter_dtm, 
    k = 5, 
    method = "VEM")

# create similar LDA 

#lda_six <- LDA(reasons_dtm,k = 6) 

# tidy the CTM model output 

twitter_ctm_topics <- ctm_1 %>%
  tidy(matrix = "beta") %>%
  arrange(desc(beta))

# arrange top 15 terms by each topic 

twitter_word_probs<- twitter_ctm_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 15) %>% 
  ungroup() %>%
  arrange(topic, -beta)

twitter_word_probs %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() + theme(axis.text=element_text(size=12)) 


twitter_ctm_topics %>% count(term)
```






```{r Common-Words}


```


```{r}
# assign topic from CTM to observations 
# use the function topics() from topicmodels library to assign the most
# likely topics for each document (in this case combined reasons) 

ctm_assignments <- data.frame(topics(ctm_1)) 
ctm_assignments$row_id <- rownames(ctm_assignments) 
colnames(ctm_assignments) <- c("topic_assigned", "row_id") 

# join topic assignment outputs with original data set using dyply's inner_join() 

topics_assigned <- inner_join(x = twitter_cleaned, 
           y = ctm_assignments, 
           by = "row_id") 
  
# check distribution of topics assigned
# shows even split between two topics 
table(topics_assigned$topic_assigned) 
```


```{r Dummy-Coding}
table(topics_assigned$topic_assigned) 

# for a 4 topic solution
# note: this will change based on the optimal number of topics identified above 
# in the study, the topic model will first be run and inter-rater reliability
# will be calculated before this step below, where the topics are assigned back 
# to the data set 

topics_assigned$topic_1 <- ifelse(topics_assigned$topic_assigned == '1', 1, 0)
topics_assigned$topic_2 <- ifelse(topics_assigned$topic_assigned == '2', 1, 0)
topics_assigned$topic_3 <- ifelse(topics_assigned$topic_assigned == '3', 1, 0)
topics_assigned$topic_4 <- ifelse(topics_assigned$topic_assigned == '4', 1, 0)

topics_assigned$topic_5 <- ifelse(topics_assigned$topic_assigned == '5', 1, 0)

topics_assigned$topic_6 <- ifelse(topics_assigned$topic_assigned == '6', 1, 0)

#topics_assigned$topic_7 <- ifelse(topics_assigned$topic_assigned == '7', 1, 0)

#topics_assigned$topic_8 <- ifelse(topics_assigned$topic_assigned == '8', 1, 0)


```


Before running analyses
```{r Data-Cleaning-2}


# create factor variable (alternative to manual dummy coding above)
topics_assigned$topic_factor <- factor(x = topics_assigned$topic_assigned, 
                          levels = c(1, 2, 3, 4, 5),
                          labels = c("Topic1", "Topic2", "Topic3", "Topic4", "Topic5")) 



# check data class for count data - likes and retweets
# remove all NA values from a
table(is.na(topics_assigned$like_count)) 



# convert retweet_count and reply_count fields to numeric 

topics_assigned$retweet_count <- as.numeric(topics_assigned$retweet_count) 
table(is.na(topics_assigned$retweet_count)) 

topics_assigned$reply_count <- as.numeric(topics_assigned$reply_count) 
table(is.na(topics_assigned$reply_count)) 

```



```{r Regression}

# standardized outcome variable 
topics_assigned$like_count <- as.numeric(topics_assigned$like_count) 
std_topic_df <- topics_assigned %>% 
  mutate(std_likes <- scale(like_count)) 


# model comparison 

lmF <- lm(like_count ~ topic_factor, 
          data = topics_assigned) 
lmF %>%
  summary() 


lm_reduced <- lm(like_count ~ 1, data = topics_assigned) 
anova(lm_reduced) 

lm_topics <- lm(like_count ~ 1 + topic_factor, 
              data = topics_assigned) 

anova(lm_topics)   
anova(lm_reduced, lm_topics)
summary(lm_topics) 
lm_full %>% summary()  

mod_comparison_1 <- anova(lm_reply, lm_full)
mod_comparison_1 

```


Set maximum threshold for word frequency.
Words that occur too often across tweets are likely to reduce the model's ability 
To generate meaningfully differentiated topics 

```{r Word-Min-Max-Threshold}

# twitter_cleaned ; df originally fed into first TM above 
# set a min and max threshold for input into topic model 
# view top terms in corpus
twitter_ctm_topics %>%
  mutate(total = beta*length(term))


# define terms to remove based on over use or under use 
threshold_remove <- c("home", "amp", "return", "il", "II", "dai", 
                      "remote", "daily", "office", "people", "job")

twitter_2 <- twitter_data %>%   
  mutate(tweets_cleaned = 
           str_remove_all(text, 
          regex(str_c("\\b",threshold_remove, "\\b", collapse = '|'), 
          ignore_case = T)))

# random sample of twitter_2 after removing threshold 
twitter_2 <- twitter_2 %>%
  sample_n(1000)

# with stem
dtm_2 <- twitter_2 %>%
  unnest_tokens(word, tweets_cleaned) %>%
  anti_join(stop_words) %>%
    mutate(stem = wordStem(word)) %>%
  count(row_id, stem) %>%
  cast_dtm(document = row_id, term = stem, value = n) %>%
  as.matrix()  

lda_1 <- LDA(dtm_2, 
    k = 5, 
    method = "VEM")


lda_1_topics <- lda_1 %>%
  tidy(matrix = "beta") %>%
  arrange(desc(beta))

# arrange top 15 terms by each topic 

lda_1_word_probs<- lda_1_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 15) %>% 
  ungroup() %>%
  arrange(topic, -beta)

lda_1_word_probs %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() + theme(axis.text=element_text(size=12))

```


```{r Regression-Analysis2}

lda_1_assignments <- data.frame(topics(lda_1)) 
lda_1_assignments$row_id <- rownames(lda_1_assignments) 
colnames(lda_1_assignments) <- c("topic_assigned", "row_id") 

# join topic assignment outputs with original data set using dyply's inner_join() 

topics_assigned_1 <- inner_join(x = twitter_2, 
           y = lda_1_assignments, 
           by = "row_id") 


topics_assigned_1$topic_1 <- ifelse(topics_assigned_1$topic_assigned == '1', 1, 0)
topics_assigned_1$topic_2 <- ifelse(topics_assigned_1$topic_assigned == '2', 1, 0)
topics_assigned_1$topic_3 <- ifelse(topics_assigned_1$topic_assigned == '3', 1, 0)
topics_assigned_1$topic_4 <- ifelse(topics_assigned_1$topic_assigned == '4', 1, 0)
topics_assigned_1$topic_5 <- ifelse(topics_assigned_1$topic_assigned == '5', 1, 0)

#topics_assigned_1$topic_6 <- ifelse(topics_assigned_1$topic_assigned == '6', 1, 0)

#topics_assigned_1$topic_7 <- ifelse(topics_assigned_1$topic_assigned == '7', 


# create factor for topic assigned 
topics_assigned_1$topic_factor <- factor(x = topics_assigned_1$topic_assigned, 
                          levels = c(1, 2, 3, 4, 5),
                          labels = c("Topic1", "Topic2", "Topic3", "Topic4", "Topic5")) 

# run omnibus test of like count regressed on topic factor; 
#null is that there is no difference in likes by topic 
lmF_1 <- lm(like_count ~ topic_factor, 
          data = topics_assigned_1) 
lmF_1 %>%
  summary() 




```






Below code chunks run STM as alternative to LDA and CTM topic models 

```{r STM-approach}

library(stm)

# remove rows with NA values 
twitter_data <- twitter_data %>%
  select(-c(X11:X18))

# clean created_at column with time stamp 
# first, remove non-date values 

# create new column month that converts the dates to a month factor to be used as coverariate 

twitter_data <- twitter_data %>%
  mutate(month = ifelse(grepl("2021-09", created_at), "Sept-2021", 
                        ifelse(grepl("2021-08", created_at), "Aug-2021",
                               ifelse(grepl("2021-07", created_at), "Jul-2021", 
                                      ifelse(grepl("2020-07", created_at), "Jul-2020", 
                                             ifelse(grepl("2020-06", created_at), "June-2020", ifelse(grepl("2020-08", created_at), "Aug-2020", 
                                                                                                      ifelse(grepl("2020-07", created_at), "Jul-2021", "NA"))))))))


twitter_data <- twitter_data %>%
  filter(!month == "NA")    


# take a random sample to limit n size 
twitter_sample <- twitter_data %>%
  group_by(month) %>%
   sample_n(500, replace = T)  


# view random sample by month 
table(twitter_sample$month) 



```



```{r generate-corpus}




# generate corpus using STM framework

processed <- textProcessor(twitter_sample$text, metadata = twitter_sample) 

out <- prepDocuments(processed$documents, processed$vocab, processed$meta) 

# search for ideal number of topics 
ntopics <- searchK(out$documents, out$vocab, K = c(2,3,4,5,6,7), data = meta)

```


Following initial diagnostic, fit a k = 3 topic model for evaluation 

```{r stm-3-topic}

fit_three <- stm(out$documents, # the documents
            out$vocab, # covariates expected to affect topic content 
            K = 3,
            prevalence =~ month, 
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral") 

sageLabels(fit_three) # only works with content covariates in the model
plot(fit_three)

# correlations between topics 
round(topicCorr(fit_three)$cor, 2) # just the correlations between topics




```









```{r}
# Turn the STM object into a data frame. This is necessary so that we can work with it.
td_beta <- tidy(fit_three)

# create re-useable function for subsequent topic model solutions 
# bar chart uses wesanderson color palettes
word_probs <- function(td_beta) { 
  
  td_beta %>%
  # Group by topic
  group_by(topic) %>%
  # Take the top 10 based on beta
  top_n(10, beta) %>%
  # Ungroup
  ungroup() %>%
  # Generate the variables topic and term
  dplyr::mutate(topic = paste0("Topic ", topic),
                term = reorder_within(term, beta, topic)) %>%
  # And plot it
  ggplot() +
  # Using a bar plot with the terms on the x-axis, the beta on the y-axis, filled by topic
  geom_col(aes(x = term, y = beta, fill = as.factor(topic)),
           alpha = 0.8,
           show.legend = FALSE) +
  # Do a facet_wrap by topic
  facet_wrap(~ topic, scales = "free_y") +
  # And flip the plot
  coord_flip() +
  scale_x_reordered() +
  # Label the x-axis, y-axis, as well as title
  labs(
    y = expression(beta),
    title = "Highest word probabilities for each topic") +
  # And finally define the colors
  scale_fill_manual(values = wes_palette("Darjeeling1"))
  
  
  }

# generate bar chart for 2 topic solution
word_probs(td_beta) 
```





```{r sentiment-analysis}

# show change in sentiment over time 
library(tidytext) 
twitter_tidy <- tibble(twitter_sample)

twitter_tidy <- tibble(twitter_sample) %>% 
  unnest_tokens(sentence, text, token = "sentences") %>%
  right_join(get_sentiments("bing")) 

# generate sentiment scores on twitter_tidy
sentiment_df <- sentiment_by(twitter_tidy$sentence) 
sentiment_df

table(twitter_tidy$month, twitter_tidy$sentiment) 


```







