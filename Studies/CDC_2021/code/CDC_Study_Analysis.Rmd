---
title: "CDC_Analysis"
output: html_notebook
---

Data analysis related to CDC compliance behaviors (2021) 

```{r Libraries-and-Path, include = F}

library(tidytext) 
library(tidyverse)
library(topicmodels) 
library(ldatuning)
library(textstem) 
library(SnowballC) 
library(tm)
library(car) 
library(stm) 

#require("knitr")
#opts_knit$set(root.dir = "/Users/gianzlupko/Desktop/Workgroup/dnl_nlp/Studies/CDC_2021/data") 

```



```{r Data-Cleaning}
# load raw data and begin conversion to long data format 
dat <- read_csv("cdc_raw_reasons.csv")

# rename columns

dat <- dat %>%
   rename(Decision = Q4, Reason1 = Q12_1, Reason2 = Q12_2, Reason3 = Q12_3, 
          Reason4 = Q12_4, Reason5 = Q12_5, Reason6 = Q12_6, Reason7 = Q12_7, 
          Reason8 = Q12_8, Reason9 = Q12_9, Reason10 = Q12_10)  


# first add unique participant id 
dat1 <- dat %>%
  mutate(participant_id = 1:length(Decision))

# use duplicated() to check that each participant_id is unique 
duplicated(dat1[ ,c("participant_id")])

# after confirming that all ids are unique
# create one data set of reasons that will be 
# used to convert from wide to long format 

dat2 <- dat1 %>%
  select(participant_id, Reason1, Reason2, Reason3, Reason3, 
         Reason4, Reason5, Reason6, Reason7, Reason8, Reason9, Reason10)  

# first convert reasons to long data format
data_long <- dat2 %>%
  gather(key = "Reason", 
         value = "Reason_Stated", c(-participant_id)) 


# next create a subset of the original data without the reasons data
# instead, retain only the BRT and decision variable scores to reattach
# to the long data frame

scores_to_merge <- dat1 %>%
  select(participant_id, ConfRfor, ConfRag, Att_Ave, SN_Ave, PC_Ave, MacroReasoning_3_items_standardized_Ave, 
         SN_general_Ave, SN_work_Ave, ProReas, ConReas)

# now, merge with the long formatted reasons data and merge by participant_id

reasons_formatted <- merge(x = data_long, 
                           y = scores_to_merge, 
                           by = "participant_id", 
                           all.y = T)


# finally remove rows with NA values 

reasons_long <- reasons_formatted %>%
  filter(!is.na(Reason_Stated)) 


# add row_id, which will be used after creating topic model
# to re-assign the topic model output back to the unique row id 
reasons_long$row_id <- paste(1:nrow(reasons_long))


```



Topic Modeling

```{r dtm-and-fit}

dtm_1 <- reasons_long %>%
  unnest_tokens(word, Reason_Stated) %>%
  anti_join(stop_words) %>%
    mutate(stem = wordStem(word)) %>%
  count(row_id, stem) %>%
  cast_dtm(document = row_id, term = stem, value = n) %>%
  as.matrix() 


# identify possible k 

seed<- 59127
number_topics <- FindTopicsNumber(
  dtm_1,
  topics = seq(from = 2, to = 15, by = 1),
  metrics = c("CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "GIBBS",
  
  control=list(seed = seed),
  mc.cores = 2L,
  verbose = TRUE
)

# it appears that an optimal number of topics are 2 or 6
FindTopicsNumber_plot(number_topics) 


```






```{r}

ctm_1 <- CTM(dtm_1, 
    k = 3, 
    method = "VEM")

# create similar LDA 

#lda_six <- LDA(reasons_dtm,k = 6) 

# tidy the CTM model output 

ctm_topics <- ctm_1 %>%
  tidy(matrix = "beta") %>%
  arrange(desc(beta))

# arrange top 15 terms by each topic 

ctm_word_probs<- ctm_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 15) %>% 
  ungroup() %>%
  arrange(topic, -beta)

ctm_word_probs %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() + theme(axis.text=element_text(size=12)) 

```




Review frequencies and determine min/max thresholds 

```{r}
# view top terms in corpus
ctm_topics %>%
  arrange(desc(beta)) 

# set a min and max threshold for input into topic model
# define terms to remove based on over use or under use 
threshold_remove <- c("sick", "covid", "spread")

# the following steps repeat those above after removing max threshold word 
reasons_long_1 <- reasons_long %>%   
  mutate(Reason_cleaned = 
           str_remove_all(Reason_Stated, 
          regex(str_c("\\b",threshold_remove, "\\b", collapse = '|'), 
          ignore_case = T)))

dtm_2 <- reasons_long_1 %>%
  unnest_tokens(word, Reason_cleaned) %>%
  anti_join(stop_words) %>%
    mutate(stem = wordStem(word)) %>%
  count(row_id, stem) %>%
  cast_dtm(document = row_id, term = stem, value = n) %>%
  as.matrix()  

ctm_2<- LDA(dtm_2, 
    k = 3, 
    method = "VEM")


ctm_2_topics <- ctm_2 %>%
  tidy(matrix = "beta") %>%
  arrange(desc(beta))

# arrange top 15 terms by each topic 

ctm_2_word_probs <- ctm_2_topics  %>%
  group_by(topic) %>%
  slice_max(beta, n = 15) %>% 
  ungroup() %>%
  arrange(topic, -beta)

ctm_2_word_probs %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() + theme(axis.text=element_text(size=12))
```



```{r 4-and-5-topic-ctm}

ctm_3 <- CTM(dtm_1, 
    k = 4, 
    method = "VEM")


# create function to store new data objects related to subjective review of model output 

word_probs <- function(mod, k) { 
  
  ctm_k_topics <- mod %>%
  tidy(matrix = "beta") %>%
  arrange(desc(beta))

# arrange top 15 terms by each topic 

ctm_k_word_probs <- ctm_k_topics  %>%
  group_by(topic) %>%
  slice_max(beta, n = 15) %>% 
  ungroup() %>%
  arrange(topic, -beta)

ctm_k_word_probs %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered() + theme(axis.text=element_text(size=12))
  

  }


word_probs(mod = ctm_3, k = 3) 



```



Structural Topic Model 

```{r structural-topic-model}

library(tidytext)

# using tidytext principles, transform data into a tidy data structure with unnest_tokens()
tidy_reasons <- reasons_long %>%
    mutate(line = row_number()) %>%
    unnest_tokens(word, Reason_Stated) %>%
    anti_join(stop_words) 

# view top words 
tidy_reasons %>%
    count(word, sort = TRUE)


library(drlib)

# create both tf-idf as well as word-by-document 
reasons_tf_idf <- tidy_reasons %>%
    count(participant_id, word, sort = TRUE) %>%
    bind_tf_idf(word, participant_id, n) %>%
    arrange(-tf_idf) %>%
    group_by(participant_id) %>%
    top_n(10) %>%
    ungroup

reasons_tf_idf

library(quanteda) 

reasons_dfm <- tidy_reasons %>%
    count(participant_id, word, sort = TRUE) %>%
    cast_dfm(participant_id, word, n)

reasons_sparse <- tidy_reasons %>%
    count(participant_id, word, sort = TRUE) %>%
    cast_sparse(participant_id, word, n)



```



```{r stm1}

# generate stm with k = 6
stm1 <- stm(reasons_dfm, K = 6, 
                   verbose = FALSE, init.type = "Spectral")

# next, use tidy() to get probabilities that each word is assigned by stm to a latent topic 
td_beta <- tidy(stm1)

td_beta %>%
    group_by(topic) %>%
    top_n(10, beta) %>%
    ungroup() %>%
    mutate(topic = paste0("Topic ", topic),
           term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(term, beta, fill = as.factor(topic))) +
    geom_col(alpha = 0.8, show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free_y") +
    coord_flip() +
    scale_x_reordered() +
    labs(x = NULL, y = expression(beta),
         title = "Highest word probabilities for each topic",
         subtitle = "Different words are associated with different topics")

```


```{r}
plot.STM(stm1, type = "summary") 


# correlations between topics 
round(topicCorr(stm1)$cor, 2) # just the correlations between topics
```


```{r stm-identify-k}

reasons_long <- reasons_long %>%
  rename(text = Reason_Stated) 

# Build the corpus
mycorpus <- corpus(reasons_long) 

# Assigns a unique identifier to each text
docvars(mycorpus, "Textno") <-
  sprintf("%02d", 1:ndoc(mycorpus)) 

token <-
  tokens(
    # Takes the corpus
    mycorpus,
    # Remove numbers
    remove_numbers = TRUE,
    # Remove punctuation
    remove_punct = TRUE,
    # Remove symbols
    remove_symbols = TRUE,
    # Remove URL
    remove_url = TRUE,
    # Split up hyphenated words
    split_hyphens = TRUE,
    # And include the doc vars (we'll need them later)
    include_docvars = TRUE
  )

# Clean tokens created by OCR
token_reasons <- tokens_select(
  token,
  c("[\\d-]", "[[:punct:]]", "^.{1,2}$"),
  selection = "remove",
  valuetype = "regex",
  verbose = TRUE
)

token_reasons <- tokens_select(token, pattern = stopwords("en"), selection = "remove")

# generate dfm object using quanteda 
reasons_dfm <- dfm(
  # Take the token object
  token_reasons,
  # Lower the words
  tolower = TRUE) 


# optional command to trim min and max frequency count 

reasons_dfm_trim <-
  dfm_trim(
    reasons_dfm,
    min_docfreq = 0.075,
    # min 7.5%
    max_docfreq = 0.95,
    #  max 90%
    docfreq_type = "prop"
  ) 


# Get the 30 top features from the DFM
freq_feature <- topfeatures(reasons_dfm, 30)

# Create a data.frame for ggplot
data <- data.frame(list(
  term = names(freq_feature),
  frequency = unname(freq_feature)
))

# Plot the plot
data %>%
  # Call ggplot
  ggplot() +
  # Add geom_segment (this will give us the lines of the lollipops)
  geom_segment(aes(
    x = reorder(term, frequency),
    xend = reorder(term, frequency),
    y = 0,
    yend = frequency
  ), color = "grey") +
  # Call a point plot with the terms on the x-axis and the frequency on the y-axis
  geom_point(aes(x = reorder(term, frequency), y = frequency)) +
  # Flip the plot
  coord_flip() +
  # Add labels for the axes
  xlab("") +
  ylab("Absolute frequency of the features")


meta_data <- dictionary(file = "cdc_raw_reasons.csv") 
# Generate the DFM with covariates
reasons_dfm_covariate  <- dfm(reasons_dfm, 
                # Based on country
                groups = "country",
                # And the previously loaded dictionary
                dictionary = dict)


ntopics <- searchK(out$documents, out$vocab, K = c(7, 10), data = meta)

```



Take 2 - per, https://blogs.uoregon.edu/rclub/2016/04/05/structural-topic-modeling/

```{r}
reasons_long <- reasons_long %>%
  rename(document = Reason_Stated) 

# test remove NA from ConfRfor
reasons_long <- reasons_long %>%
  filter(!is.na(ConfRfor)) 

# uses textProcessor() function from tm package 
processed <- textProcessor(reasons_long$document, metadata = reasons_long)
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)

fit0 <- stm(out$documents, # the documents
            out$vocab, # the words
            K = 4, # 10 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral")  

# look at top words
labelTopics(fit0)

plot.STM(fit0, type = "summary") 

# correlations between topics 
round(topicCorr(fit0)$cor, 2) # just the correlations between topics




```


```{r, include F}
# identify best k
ntopics <- searchK(out$documents, out$vocab, K = c(2, 10), data = meta)

# 
plot(ntopics)

# selectModel() approach can also be used in addition to searchK() 
# whereby models are selected that optimize on exclusivity and semantic coherence 

stm_select_mod <- selectModel(out$documents, out$vocab, K = 15, 
                              prevalence = ~ConfRfor, max.em.its = 75, data = out$meta, 
                              runs = 15) 

plotModels(stm_select_mod, pch = c(1,2,3,4), legend.position = "bottomright")
```

```{r stm-add-covariate}

fit1 <- stm(out$documents, # the documents
            out$vocab, # covariates expected to affect topic content 
            prevalence =~ participant_id + SN_Ave + PC_Ave,
            K = 3, # 4 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral") 

sageLabels(fit1) # only works with content covariates in the model
plot(fit1)

# correlations between topics 
round(topicCorr(fit0)$cor, 2) # just the correlations between topics
round(topicCorr(fit1)$cor, 2)
```


```{r}
# Turn the STM object into a data frame. This is necessary so that we can work with it.
td_beta <- tidy(fit1)
library(wesanderson)
td_beta %>%
  # Group by topic
  group_by(topic) %>%
  # Take the top 10 based on beta
  top_n(10, beta) %>%
  # Ungroup
  ungroup() %>%
  # Generate the variables topic and term
  dplyr::mutate(topic = paste0("Topic ", topic),
                term = reorder_within(term, beta, topic)) %>%
  # And plot it
  ggplot() +
  # Using a bar plot with the terms on the x-axis, the beta on the y-axis, filled by topic
  geom_col(aes(x = term, y = beta, fill = as.factor(topic)),
           alpha = 0.8,
           show.legend = FALSE) +
  # Do a facet_wrap by topic
  facet_wrap(~ topic, scales = "free_y") +
  # And flip the plot
  coord_flip() +
  scale_x_reordered() +
  # Label the x-axis, y-axis, as well as title
  labs(
    y = expression(beta),
    title = "Highest word probabilities for each topic") +
  # And finally define the colors
  scale_fill_manual(values = wes_palette("Darjeeling1"))

```


```{r}
# look at highest word probability
labelTopics(fit1)

plot.STM(fit1, type = "labels") 

plot.STM(fit1, type = "summary") 
# look at 

# outputs most representative documents for a particular topic
findThoughts(
  # Your topic model
  fit1,
  texts = token_reasons, 
  n = 3, 
  topics = c(1,2,3)
)
```


Use model outputs to assign categorical variables for regression 

```{r}
est1 <- estimateEffect(1:3 ~ Att_Ave, stmobj = fit1, metadata = out$meta)   

summary(est1) 

plot(est1, covariate = "Att_Ave", topics = c(1,2), 
     model = fit1, 
     method = "continuous") 
```



```{r}



fit2 <- stm(out$documents, # the documents
            out$vocab, # covariates expected to affect topic content 
            prevalence =~ Att_Ave,
            K = 3, # 4 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral") 

est2 <- estimateEffect(1:3 ~ Att_Ave, stmobj = fit2, metadata = out$meta)   

summary(est2) 

# plot the relationship between topic and attitude
plot(est2, covariate = "Att_Ave", topics = c(1), 
     model = fit2, 
     method = "continuous") 
plot(est2, covariate = "Att_Ave", topics = c(2), 
     model = fit2, 
     method = "continuous") 
plot(est2, covariate = "Att_Ave", topics = c(3), 
     model = fit2, 
     method = "continuous") 





```


```{r extract-estimate-effects}

library(tidystm)


est1 <- estimateEffect(1:3 ~ Att_Ave, stmobj = fit1, metadata = out$meta)   
## Estimate the effect on all three topics and return the point
## estimates in a tidy data frame
effect <- extract.estimateEffect(est1, "Att_Ave", model = fit1, method = "pointestimate") 


knitr::kable(effect)


```



TopicCorr

```{r}
# correlations between topics 
topicCorr(fit1, cutoff = 0.01) 
```




Reasons Against Data 



```{r Against-Data-Cleaning}
# rename columns

against <- dat %>%
   rename(Against1 = Q33_1, Against2 = Q33_2, Against3 = Q33_3, 
          Against4 = Q33_4, Against5 = Q33_5, Against6 = Q33_6, Against7 = Q33_7, 
          Against8 = Q33_8, Against9 = Q33_9, Against10 = Q33_10)  


# first add unique participant id 
against1 <- against %>%
  mutate(participant_id = 1:length(Decision))

# use duplicated() to check that each participant_id is unique 
duplicated(against1[ ,c("participant_id")])

# after confirming that all ids are unique
# create one data set of reasons that will be 
# used to convert from wide to long format 

against_df <- against1 %>%
  select(participant_id, Against1, Against2, Against3, Against4, 
         Against5, Against6, Against7, Against8, Against9, Against10)  

# first convert reasons to long data format
against_long <- against_df %>%
  gather(key = "Against", 
         value = "Against_Stated", c(-participant_id)) 


# next create a subset of the original data without the reasons data
# instead, retain only the BRT and decision variable scores to reattach
# to the long data frame

against_to_merge <- against1 %>%
  select(participant_id, ConfRfor, ConfRag, Att_Ave, SN_Ave, PC_Ave, MacroReasoning_3_items_standardized_Ave, 
         SN_general_Ave, SN_work_Ave, ProReas, ConReas)

# now, merge with the long formatted reasons data and merge by participant_id

against_formatted <- merge(x = against_long, 
                           y = against_to_merge, 
                           by = "participant_id", 
                           all.y = T)


# finally remove rows with NA values 

against_long <- against_formatted %>%
  filter(!is.na(Against_Stated)) 


# add row_id, which will be used after creating topic model
# to re-assign the topic model output back to the unique row id 
against_long$row_id <- paste(1:nrow(against_long))
```


STM processing and model diagnostics 
```{r}

# renmae Against_Stated to 'document' for tm processing 
against_long <- against_long %>%
  rename(document = Against_Stated) 

# uses textProcessor() function from tm package 
against_processed <- textProcessor(against_long$document, metadata = against_long)

against_out <- prepDocuments(against_processed$documents, 
                             against_processed$vocab, 
                             against_processed$meta)


# two methods for identifying model fit 

# identify best k
ntopics <- searchK(against_out$documents, against_out$vocab, K = c(2, 10), data = meta)

# 
plot(ntopics)

# selectModel() approach can also be used in addition to searchK() 
# whereby models are selected that optimize on exclusivity and semantic coherence 

stm_select_mod <- selectModel(against_out$documents, against_out$vocab, K = 8, 
                              prevalence = ~participant_id, max.em.its = 75, data = against_out$meta, 
                              runs = 15) 

plotModels(stm_select_mod, pch = c(1,2,3,4), legend.position = "bottomright")


against_fit_1 <- stm(against_out$documents, # the documents
            against_out$vocab, # the words
            K = 3, # 3 topics
            max.em.its = 75, # set to run for a maximum of 75 EM iterations
            data = against_out$meta, # all the variables (we're not actually including any predictors in this model, though)
            init.type = "Spectral")  

# look at top words
labelTopics(against_fit_1)

plot.STM(against_fit_1, type = "summary") 

# correlations between topics 
round(topicCorr(against_fit_1)$cor, 2) # just the correlations between topics


td_against_beta <- tidy(against_fit_1)
library(wesanderson)
td_against_beta %>%
  # Group by topic
  group_by(topic) %>%
  # Take the top 10 based on beta
  top_n(10, beta) %>%
  # Ungroup
  ungroup() %>%
  # Generate the variables topic and term
  dplyr::mutate(topic = paste0("Topic ", topic),
                term = reorder_within(term, beta, topic)) %>%
  # And plot it
  ggplot() +
  # Using a bar plot with the terms on the x-axis, the beta on the y-axis, filled by topic
  geom_col(aes(x = term, y = beta, fill = as.factor(topic)),
           alpha = 0.8,
           show.legend = FALSE) +
  # Do a facet_wrap by topic
  facet_wrap(~ topic, scales = "free_y") +
  # And flip the plot
  coord_flip() +
  scale_x_reordered() +
  # Label the x-axis, y-axis, as well as title
  labs(
    y = expression(beta),
    title = "Highest word probabilities for each topic",
 subtitle = "Reasons Against") +
  # And finally define the colors
  scale_fill_manual(values = wes_palette("Zissou1"))


```


Reasons Against - Estimated Effects 
```{r}
against_est1 <- estimateEffect(1:3 ~ Att_Ave, stmobj = against_fit_1, metadata = against_out$meta)   

summary(against_est1) 

plot(against_est1, covariate = "Att_Ave", topics = c(2), 
     model = against_fit_1, 
     method = "continuous", xlab = "Attitude")
```


