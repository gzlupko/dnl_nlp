# NLP Code for Dynamic Network Lab Research
NLP code repo for DNL research



Example figure - LDA density plot. The minimum value of the density statistic corresponds to the statisticallay optimal number of topics to retain. 

![alt text](https://github.com/gzlupko/dnl_nlp/blob/main/lda_density_fit.png)



Example Figure - Top terms by topic using Latent Dirichlet Allocation (LDA) on sample Twitter data (N= 53,000+) 

![alt text](https://github.com/gzlupko/dnl_nlp/blob/main/term_by_topic_example.png)





Sample Decision Data (N = 239) 


Below is an LDA density plot for the decisions that participants listed. The density plot provides one indication for the ideal number of topics in the text data. The density plot shows the probabilities of overlap of terms in topics for a particular solution. The lower the density (of overlap), the better the solution as low term overlap will help the researcher subjectively differentiate the topics and provide definitions for the topics based on their unique terms. 

![alt text](https://github.com/gzlupko/dnl_nlp/blob/main/topic_density_stemmed_plot.png)

Below are the top terms for each of the three topics in the recommended three topic solution. 

![alt text](https://github.com/gzlupko/dnl_nlp/blob/main/reasons_stemmed_plot.png)



The below table shows the probabilities of each topic occuring in the corpus (overall collection of text data) as well as the the probability of each term occuring in the corpus. Note: this is based on a three-topic solution, which is recommended by the density statistic as well as a subjective content review of the groupings. 

![alt text](https://github.com/gzlupko/dnl_nlp/blob/main/beta_gamma_sample.png)






Sentiment Analysis 

Below are word counts and associated sentiments for sample airline review Twitter data. 


![alt text](https://github.com/gzlupko/dnl_nlp/blob/main/sentiment_count.png)
